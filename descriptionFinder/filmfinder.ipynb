{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.classify import PositiveNaiveBayesClassifier\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "\n",
    "#nltk.download()\n",
    "stop_words = set(stopwords.words('english')) \n",
    "porterStemmer = nltk.stem.PorterStemmer()\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LemTokens(tokens):\n",
    "    tokens = [porterStemmer.stem(token) for token in tokens]\n",
    "    l = [lemmer.lemmatize(token) for token in tokens]\n",
    "    return l\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(remove_punct_dict)\n",
    "    l = nltk.word_tokenize(text)\n",
    "    filtered_sentence = [w for w in l if not w in stop_words]\n",
    "    return LemTokens(filtered_sentence)\n",
    "\n",
    "\n",
    "\n",
    "com = set()\n",
    "horr = set()\n",
    "scifi = set()\n",
    "crime = set()\n",
    "drama = set()\n",
    "\n",
    "filepath = \"scifi.txt\"\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        scifi.add(lemmer.lemmatize(line.rstrip()))\n",
    "        line = fp.readline()\n",
    "filepath = \"crime.txt\"\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        crime.add(lemmer.lemmatize(line.rstrip()))\n",
    "        line = fp.readline()\n",
    "filepath = \"drama.txt\"\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        drama.add(lemmer.lemmatize(line.rstrip()))\n",
    "        line = fp.readline()\n",
    "\n",
    "\n",
    "filepath = \"horror.txt\"\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        horr.add(lemmer.lemmatize(line.rstrip()))\n",
    "        line = fp.readline()\n",
    "                 \n",
    "filepath = \"comedy.txt\"\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        com.add(lemmer.lemmatize(line.rstrip()))\n",
    "        line = fp.readline()\n",
    "        \n",
    "\n",
    "train = [\n",
    "    \n",
    "    (dict([('contains-word(%s)' % w, True) for w in com]), 'comedy'),\n",
    "    (dict([('contains-word(%s)' % w, True) for w in horr]), 'horror'),\n",
    "    (dict([('contains-word(%s)' % w, True) for w in crime]), 'crime'),\n",
    "    (dict([('contains-word(%s)' % w, True) for w in drama]), 'drama'),\n",
    "    (dict([('contains-word(%s)' % w, True) for w in scifi]), 'scifi'),\n",
    "    ]\n",
    "test = [\n",
    "    (dict([('contains-word(%s)' % w, True) for w in [\"art\", \"drollery\"]])),\n",
    "    (dict([('contains-word(%s)' % w, True) for w in [\"scary\", \"danger\"]])),\n",
    "    (dict([('contains-word(%s)' % w, True) for w in [\"gun\", \"police\"]]))\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train)\n",
    "sorted(classifier.labels())\n",
    "#classifier.classify_many(test)\n",
    "#for pdist in classifier.prob_classify_many(test):\n",
    "    #print('%.4f %.4f %.4f %.4f %.4f' % (pdist.prob('horror'), pdist.prob('comedy'),pdist.prob('crime'),pdist.prob('scifi'),pdist.prob('drama')))\n",
    "\n",
    "    \n",
    "vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\")\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    " \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "        \n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimeMovie = {}\n",
    "dramaMovie = {}\n",
    "comedyMovie = {}\n",
    "horrorMovie = {}\n",
    "scifiMovie = {}\n",
    "\n",
    "\n",
    "\n",
    "d = pd.read_csv('movie3.csv')\n",
    "for x,y in zip(d['overview'],d['title']):\n",
    "    words = LemNormalize(x)\n",
    "    testWords =[(dict([('contains-word(%s)' % w, True) for w in words]))]\n",
    "    for pdist in classifier.prob_classify_many(testWords):\n",
    "        #print('%.4f %.4f %.4f %.4f %.4f' % (pdist.prob('horror'), pdist.prob('comedy'),pdist.prob('crime'),pdist.prob('scifi'),pdist.prob('drama')))\n",
    "        coeff = max((pdist.prob('horror'), pdist.prob('comedy'),pdist.prob('crime'),pdist.prob('scifi'),pdist.prob('drama')))\n",
    "        if coeff == pdist.prob('horror'):\n",
    "            horrorMovie[y] = x\n",
    "        elif coeff == pdist.prob('comedy'):\n",
    "            comedyMovie[y] = x\n",
    "        elif coeff == pdist.prob('scifi'):\n",
    "            scifiMovie[y] = x\n",
    "        elif coeff == pdist.prob('crime'):\n",
    "            crimeMovie[y] = x\n",
    "        else:\n",
    "            dramaMovie[y] = x\n",
    "            \n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def searchGenre(text, gList):\n",
    "    best= []\n",
    "    for x in gList:\n",
    "        sim = cosine_sim(text,gList[x])\n",
    "        if sim>0:\n",
    "            best.append((sim, x))\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def response(user_response):\n",
    "    bot_response=''\n",
    "    most_possible = [] \n",
    "    words = LemNormalize(user_response)\n",
    "    testWords =[(dict([('contains-word(%s)' % w, True) for w in words]))]\n",
    "    for pdist in classifier.prob_classify_many(testWords):\n",
    "        coeff = max((pdist.prob('horror'), pdist.prob('comedy'),pdist.prob('crime'),pdist.prob('scifi'),pdist.prob('drama')))\n",
    "        if coeff == pdist.prob('horror'):\n",
    "            most_possible = searchGenre(user_response,horrorMovie)\n",
    "        elif coeff == pdist.prob('comedy'):\n",
    "            most_possible = searchGenre(user_response,comedyMovie)\n",
    "        elif coeff == pdist.prob('scifi'):\n",
    "            most_possible = searchGenre(user_response,scifiMovie)\n",
    "        elif coeff == pdist.prob('crime'):\n",
    "            most_possible = searchGenre(user_response,crimeMovie)\n",
    "        else:\n",
    "            most_possible = searchGenre(user_response,dramaMovie)\n",
    "            \n",
    "    most_possible = sorted(most_possible,reverse = True)\n",
    "    return most_possible[:3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Give description about movie. If you want to exit, type Bye!\n",
      "hello\n",
      "Bot: hi\n",
      "big killer with knife and ghost christmas\n",
      "Bot: Striking Distance, Once Upon a Time in America, The Manchurian Candidate, \n",
      " [(0.06612665654870567, 'Striking Distance'), (0.06261451546913586, 'Once Upon a Time in America'), (0.05699752852140605, 'The Manchurian Candidate')]\n",
      "\n",
      "Can I help with any other film?\n",
      "no\n",
      "Bot: Bye!\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"Bot: Give description about movie. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    \n",
    "    if(user_response!='bye' and user_response!='no'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"Bot: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"Bot: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"Bot: \",end=\"\")\n",
    "                l = response(user_response)\n",
    "                if not l:\n",
    "                    print(\"Sorry! No reference.\")\n",
    "                else:\n",
    "                    for film in l:\n",
    "                        print(film[1],end =\", \"),\n",
    "                    print('\\n',response(user_response))\n",
    "                    print(\"\")\n",
    "                print(\"Can I help with any other film?\")\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Bot: Bye!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
